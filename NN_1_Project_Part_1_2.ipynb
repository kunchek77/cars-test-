{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " NN_1_Project_Part_1_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunchek77/cars-test-/blob/main/NN_1_Project_Part_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnYg-nk98bSC"
      },
      "source": [
        "DOMAIN: Electronics and Telecommunication\n",
        "\n",
        "• CONTEXT: A communications equipment manufacturing company has a product which is responsible for emitting\n",
        "informative signals. Company wants to build a machine learning model which can help the company to predict the\n",
        "equipment’s signal quality using various parameters.\n",
        "\n",
        "• DATA DESCRIPTION: The data set contains information on various signal tests performed:\n",
        "\n",
        "1. Parameters: Various measurable signal parameters.\n",
        "\n",
        "2. Signal_Quality: Final signal strength or quality\n",
        "\n",
        "• PROJECT OBJECTIVE: The need is to build a regressor which can use these parameters to determine the signal strength or\n",
        "quality [as number].\n",
        "\n",
        "Steps and tasks: [ Total Score: 10 points]\n",
        "\n",
        "1. Import data.\n",
        "\n",
        "2. Data analysis & visualisation\n",
        "\n",
        "• Perform relevant and detailed statistical analysis on the data.\n",
        "\n",
        "• Perform relevant and detailed uni, bi and multi variate analysis.\n",
        "\n",
        "Hint: Use your best analytical approach. Even you can mix match columns to create new columns which can be used for better\n",
        "analysis. Create your own features if required. Be highly experimental and analytical here to find relevant hidden patterns.\n",
        "\n",
        "3. Design, train, tune and test a neural network regressor.\n",
        "\n",
        "Hint: Use best approach to refine and tune the data or the model. Be highly experimental here.\n",
        "\n",
        "4. Pickle the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihGQ-IanxlJJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkHaArbO8kSL"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import keras as kr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential # Forward prop\n",
        "from keras.layers import Dense, Activation, LeakyReLU,ReLU\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Ve3SgQ_J0T"
      },
      "source": [
        "Setting the display layout for the coding environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcO5-C3k_Wik"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "print(\"Tensor Flow Version: \",tf.__version__)\n",
        "print(\"Keras Version: \",kr.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kRZ9ptm_ZZu"
      },
      "source": [
        "Import Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTyhQVXfLsTb"
      },
      "source": [
        "df=pd.read_csv(\"/content/Part- 1,2&3 - Signal (1).csv\")  # read csv file with \";\" as seprators\n",
        "df.head()  # Display top 5 rows of the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtjdhuD2--aN"
      },
      "source": [
        "2. Data analysis & visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E_htBO4Askz"
      },
      "source": [
        " df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PK-WUitA3c6"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn1Q-NcHA3i3"
      },
      "source": [
        "#Data type of each attribute \n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EXQNKvFBDOD"
      },
      "source": [
        "df.describe(include=\"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2DrvPEuBDYi"
      },
      "source": [
        "#Checking the presence of missing values\n",
        "df.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6b9NlSdBRZr"
      },
      "source": [
        "df.isnull().sum()   # Any of the values in the dataframe is a missing value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksidUHhiLu7"
      },
      "source": [
        "Perform relevant and detailed uni, bi and multi variate analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxZn8W85BRis"
      },
      "source": [
        "df.hist(figsize=(20,20),color=\"orange\",grid=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AqwisLshM2Z"
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6qhruLf33k"
      },
      "source": [
        "cor=df.corr()\n",
        "cor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7tABPFCgGDC"
      },
      "source": [
        "# However we want to see correlation in graphical representation so below is function for that in HEATMAP \n",
        "plt.subplots(figsize=(10,8))\n",
        "sns.heatmap(cor,annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyx1mv6Whbuu"
      },
      "source": [
        "1.Parameter 6 and Parameter 7 are highly correlated with each other and visce versa and they have almost 0 correlation with other Parameters \n",
        "\n",
        "2.Parameter 1 is positively correlated to Parameter 3 and Parameter 8 and negatively correlated to Parameter 2 and Parameter 9. \n",
        "\n",
        "3.Parameter 4 is has very low correlation with other Parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOlq1H4gGOe"
      },
      "source": [
        "sns.pairplot(df.iloc[:,1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYadjwiaiD9q"
      },
      "source": [
        "# Checking the presence of outliers\n",
        "l = len(df)\n",
        "col = list(df.columns)\n",
        "#col.remove('condition')\n",
        "for i in np.arange(len(col)):\n",
        "    sns.boxplot(x= df[col[i]], color='cyan')\n",
        "    plt.show()\n",
        "    print('Boxplot of ',col[i])\n",
        "    #calculating the outiers in attribute \n",
        "    Q1 = df[col[i]].quantile(0.25)\n",
        "    Q2 = df[col[i]].quantile(0.50)\n",
        "    Q3 = df[col[i]].quantile(0.75) \n",
        "    IQR = Q3 - Q1\n",
        "    L_W = (Q1 - 1.5 *IQR)\n",
        "    U_W = (Q3 + 1.5 *IQR)    \n",
        "    print('Q1 is : ',Q1)\n",
        "    print('Q2 is : ',Q2)\n",
        "    print('Q3 is : ',Q3)\n",
        "    print('IQR is:',IQR)\n",
        "    print('Lower Whisker, Upper Whisker : ',L_W,',',U_W)\n",
        "    bools = (df[col[i]] < (Q1 - 1.5 *IQR)) |(df[col[i]] > (Q3 + 1.5 * IQR))\n",
        "    print('Out of ',l,' rows in data, number of outliers are:',bools.sum())   #calculating the number of outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3gEgH2-hlgp"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ARnDdGrhM66"
      },
      "source": [
        "# create a boxplot for all the continuous features\n",
        "df.boxplot(column = ['Parameter 1', 'Parameter 2', 'Parameter 3', 'Parameter 4',\n",
        "       'Parameter 5', 'Parameter 6', 'Parameter 7', 'Parameter 8',\n",
        "       'Parameter 9', 'Parameter 10', 'Parameter 11', 'Signal_Strength'], figsize = (20,10)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM9vI22FhWba"
      },
      "source": [
        "we see outliers in almost very parameter however highest in 4,6,7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA6_8Y4ric45"
      },
      "source": [
        "Design, train, tune and test a neural network regressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z18494ygnrwE"
      },
      "source": [
        "# counting the number of classes in output\n",
        "df['Signal_Strength'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud0LyKPnovhx"
      },
      "source": [
        "#import pickle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgYnvFUshxLz"
      },
      "source": [
        "X = df.drop(\"Signal_Strength\", axis=1)\n",
        "y = df['Signal_Strength']             \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iT-SVTvnrzf"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISSztL5bofFJ"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pTu98x92eeX"
      },
      "source": [
        "yc = to_categorical(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91aO7RDRY2Gi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "tf.keras.backend.clear_session()\n",
        "# splitting data for test of categorial \n",
        "Xcv_train, Xc_test, ycv_train, yc_test = train_test_split(X, yc, test_size=.20, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-fozy-b25N2"
      },
      "source": [
        "print(\"Shape of y_train:\", ycv_train.shape)\n",
        "print(\"One value of y_train:\", ycv_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThE7EOs42_8h"
      },
      "source": [
        "# splitting data for  train and validation of categorial \n",
        "Xc_train, Xc_val, yc_train, yc_val = train_test_split(Xcv_train, ycv_train, test_size=.20, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bobsCE103Flo"
      },
      "source": [
        "print(\"Shape of y_train:\", yc_train.shape)\n",
        "print(\"One value of y_train:\", yc_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZjDxudWltN9"
      },
      "source": [
        "Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1OCMhrn3UTf"
      },
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAJx_gdj2opN"
      },
      "source": [
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(11,)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AizciyjBms-w"
      },
      "source": [
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(128,kernel_initializer='normal', activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aty4KT36mtB9"
      },
      "source": [
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(60,kernel_initializer='normal'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjACypwKmtE3"
      },
      "source": [
        "#Add 3rd hidden layer\n",
        "model.add(tf.keras.layers.Dense(32,kernel_initializer='normal'))\n",
        "model.add(LeakyReLU(alpha=0.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-3SxYJjsWe7"
      },
      "source": [
        "#Add 4th hidden layer\n",
        "model.add(tf.keras.layers.Dense(16,kernel_initializer='normal'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcAL9hIkmtK6"
      },
      "source": [
        "#Add OUTPUT layer\n",
        "model.add(tf.keras.layers.Dense(9, kernel_initializer='normal',activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrQraM80mtNA"
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam',loss='mean_absolute_error', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVOgQrBtoXvw"
      },
      "source": [
        "Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhQ7JnPB0ox"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLQF5G8SrfRA"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndh9PKhLrpP_"
      },
      "source": [
        "  EPOCH=300\n",
        "  model_cal=model.fit(x=Xc_train, y=yc_train, batch_size=32, epochs= EPOCH, validation_data=(Xc_val, yc_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Eyl4vf0BD-"
      },
      "source": [
        "loss_train = model_cal.history['loss']\n",
        "loss_val = model_cal.history['val_loss']\n",
        "epochs = range(1,EPOCH+1)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flgcXcJP97AV"
      },
      "source": [
        "Acc_train = model_cal.history['accuracy']\n",
        "Acc_val = model_cal.history['val_accuracy']\n",
        "epochs = range(1,EPOCH+1)\n",
        "plt.plot(epochs, Acc_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, Acc_val, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N10xFEQkdBSq"
      },
      "source": [
        "Pickle the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_jQNOW9_Fze"
      },
      "source": [
        "#import pickle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHJjTZn7cVfE"
      },
      "source": [
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYyPPB9i_3c1"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veUSIk0f_iyJ"
      },
      "source": [
        "# load the model\n",
        "model_cl = model.load_weights('/content/model.h5')\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mMTnadMH6kX"
      },
      "source": [
        "score = model.evaluate(Xc_train, yc_train, verbose = 0) \n",
        "\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUtEYRelJLO7"
      },
      "source": [
        "# score of test data\n",
        "score_t = model.evaluate(Xc_test, yc_test, verbose=0)\n",
        "print( score_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNul5iOFgOl4"
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Pqkdq8ghc5"
      },
      "source": [
        "print(y_pred[0])\n",
        "print(y_pred[1])\n",
        "print(y_pred[2])\n",
        "print(y_pred[3])\n",
        "print(y_pred[4])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}