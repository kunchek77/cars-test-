{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN 1 - Project - part 4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP+Cs3UmefJYnsEsuRfiNsQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunchek77/cars-test-/blob/main/NN_1_Project_part_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KXdU8utLQD6"
      },
      "source": [
        "DOMAIN: Autonomous Vehicles\n",
        "\n",
        "• BUSINESS CONTEXT: A Recognising multi-digit numbers in photographs captured at street level is an important component of modern-day map making. A classic example of a corpus of such street-level photographs is Google’s Street View imagery composed of hundreds of millions of geo-located 360-degree panoramic images.\n",
        "\n",
        "The ability to automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed number with a known street address helps pinpoint, with a high degree of accuracy, the location of the building it represents. More broadly, recognising numbers in photographs is a problem of interest to the optical character recognition community.\n",
        "\n",
        "While OCR on constrained domains like document processing is well studied, arbitrary multi-character text recognition in photographs is still highly challenging. This difficulty arises due to the wide variability in the visual appearance of text in the wild on account of a large range of fonts, colours, styles, orientations, and character arrangements.\n",
        "\n",
        "The recognition problem is further complicated by environmental factors such as lighting, shadows, specularity, and occlusions as well as by image acquisition factors such as resolution, motion, and focus blurs. In this project, we will use the dataset with images centred around a single digit (many of the images do contain some distractors at the sides). Although we are taking a sample of the data which is simpler, it is more complex than MNIST because of the distractors.\n",
        "\n",
        "DATA DESCRIPTION: The SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with the minimal requirement on data formatting but comes from a significantly harder, unsolved, real-world problem (recognising digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n",
        "\n",
        "Where the labels for each of this image are the prominent number in that image i.e. 2,6,7 and 4 respectively.\n",
        "\n",
        "The dataset has been provided in the form of h5py files. You can read about this file format here: http:// docs.h5py.org/en/stable/high/dataset.html\n",
        "\n",
        "Acknowledgement: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. PDF\n",
        "http://ufldl.stanford.edu/housenumbers as the URL for this site when necessary\n",
        "\n",
        "\n",
        "• PROJECT OBJECTIVE: We will build a digit classifier on the SVHN (Street View Housing Number) dataset. Steps and tasks: [ Total Score: 30 points]\n",
        "\n",
        "1. Import the data.\n",
        "\n",
        "2. Data pre-processing and visualisation.\n",
        "\n",
        "3. Design, train, tune and test a neural network image classifier.\n",
        "\n",
        "Hint: Use best approach to refine and tune the data or the model. Be highly experimental here to get the best accuracy out of the model.\n",
        "\n",
        "4. Plot the training loss, validation loss vs number of epochs and training accuracy, validation accuracy vs number of\n",
        "epochs plot and write your observations on the same.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu5W8UwzL8ov"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9uxK5gOVtsl"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import keras as kr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rau67UARMExS"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "print(\"Tensor Flow Version: \",tf.__version__)\n",
        "print(\"Keras Version: \",kr.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GegrmH0eWJ5q"
      },
      "source": [
        "Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CIpmamYVr9L"
      },
      "source": [
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXH7HGaXFjs"
      },
      "source": [
        "data1=h5py.File('/content/drive/MyDrive/ColabNotebooks/Neural Networks -NN/SVHN_single_grey1.h5.zip (Unzipped Files)/SVHN/SVHN_single_grey1.h5','r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDRjb1vYIuA_"
      },
      "source": [
        "data1.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITxnaLYJU_mT"
      },
      "source": [
        "Data pre-processing & visualisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvGJ1VsMSe3Q"
      },
      "source": [
        "#Load the training, testing, and validation data\n",
        "X_train=data1['X_train']\n",
        "X_test=data1['X_test']\n",
        "X_val=data1['X_val']\n",
        "y_train=data1['y_train']\n",
        "y_test=data1['y_test']\n",
        "y_val=data1['y_val']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anMOIrfSSe6R"
      },
      "source": [
        "# Printing the shape and data type of training, testing, and validation data\n",
        "print(\"Training data X-- Shape :\", X_train.shape,\"and Data Type : \", X_train.dtype)\n",
        "print(\"Testing data X-- Shape :\", X_test.shape,\"and Data Type : \", X_test.dtype)\n",
        "print(\"Validation data X-- Shape :\", X_val.shape,\"and Data Type : \", X_val.dtype)\n",
        "print(\"Training data y-- Shape :\", y_train.shape,\"and Data Type : \", y_train.dtype)\n",
        "print(\"Testing data y-- Shape :\", y_test.shape,\"and Data Type : \", y_test.dtype)\n",
        "print(\"Validation data y-- Shape :\", y_val.shape,\"and Data Type : \", y_val.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKy9fD3LSe9J"
      },
      "source": [
        "fig=plt.figure(figsize=(8,8))\n",
        "columns=10\n",
        "rows=10\n",
        "for i in range(1, columns*rows+1):\n",
        "    img=X_test[i]\n",
        "    fig.add_subplot(rows,columns,i)\n",
        "    plt.imshow(img,cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05NQWmqfS2ca"
      },
      "source": [
        "# show the number in the dataset\n",
        "plt.imshow(X_train[3],cmap='gray')    \n",
        "plt.show()\n",
        "print('Label: ', y_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76oK73MkS2fB"
      },
      "source": [
        "\n",
        "# show the number in the dataset\n",
        "plt.imshow(X_test[0],cmap='gray')    \n",
        "plt.show()\n",
        "print('Label: ', y_test[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mfQYa2iS2hl"
      },
      "source": [
        "\n",
        "# visualizing the first 20 images in the dataset and their labels\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20, 1))\n",
        "for i in range(20):\n",
        "    plt.subplot(1, 20, i+1)\n",
        "    plt.imshow(X_train[i].reshape(32,32),cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "print('label for each of the above image: %s' % (y_train[0:20]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SroJTJ1XTf95"
      },
      "source": [
        "Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWjMRb34mokH"
      },
      "source": [
        "\n",
        "#Reshape data from 2D to 1D -> 32X32 to 1024\n",
        "X_train = np.asarray(X_train).reshape(42000,1024)\n",
        "X_test = np.asarray(X_test).reshape(18000,1024)\n",
        "X_val = np.asarray(X_val).reshape(60000,1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZjqeaUTof0"
      },
      "source": [
        "Convert Output label to multiple values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7So_FuAEmwNw"
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "\n",
        "print(X_train.shape, X_test.shape,X_val.shape, y_train.shape, y_test.shape,y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfw3s7cXXlOR"
      },
      "source": [
        "Build the Graph..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaiA-ofNbOib"
      },
      "source": [
        "#Clear out model from current memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize Sequential model\n",
        "model = Sequential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Cow9slkBxi"
      },
      "source": [
        " model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrP3tZfvUWXR"
      },
      "source": [
        "# Input Layer\n",
        "#Input layer and activation functions ReLU\n",
        "model.add(Dense(256, kernel_initializer='he_normal',input_shape = (1024, )))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#Hidden Layer 1\n",
        "model.add(Dense(128, kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#Hidden Layer 2\n",
        "model.add(Dense(64, kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#Hidden Layer 3\n",
        "model.add(Dense(32, kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(10, kernel_initializer='he_normal', \n",
        "                                activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6WPSs4lc4S9"
      },
      "source": [
        "#Compile the model\n",
        "sgd = optimizers.Adam(lr=1e-3)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxwuv_1CdEd3"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_val,y_val),batch_size = 300, epochs = 100, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wecQl1WKUWaV"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkEN-oLWUWdJ"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Loss:\", scores[0])\n",
        "print(\"Accuracy:\", scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IheR2hVgouKW"
      },
      "source": [
        "Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a98d3h8QoUwP"
      },
      "source": [
        "accuracy      = history.history['accuracy']\n",
        "val_accuracy  = history.history['val_accuracy']\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs   = range(len(accuracy)) # Get number of epochs\n",
        "\n",
        "plt.plot  ( epochs, accuracy, label = 'training accuracy' )\n",
        "plt.plot  ( epochs, val_accuracy, label = 'validation accuracy' )\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot  ( epochs, loss, label = 'training loss' )\n",
        "plt.plot  ( epochs, val_loss, label = 'validation loss' )\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title ('Training and validation loss'   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uabpQzZ1pGrC"
      },
      "source": [
        "#Showing the image\n",
        "plt.imshow(X_test[5].reshape(32,32),cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39V__jH8pGtr"
      },
      "source": [
        "\n",
        "#Predicting the digits\n",
        "model.predict_classes(X_test)[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKjsdFNFpGwV"
      },
      "source": [
        "#Showing the image\n",
        "plt.imshow(X_test[20].reshape(32,32),cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY6RGxawpUcG"
      },
      "source": [
        "#Predicting the digits\n",
        "model.predict_classes(X_test)[20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leCPYctipgrs"
      },
      "source": [
        "#Showing the image\n",
        "plt.imshow(X_test[199].reshape(32,32),cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWzBKSZcpguU"
      },
      "source": [
        "#Predicting the digits\n",
        "model.predict_classes(X_test)[199]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn6wOtSHqTjZ"
      },
      "source": [
        "This NN model has 77% accuracy after tring many hyper parameters . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Q_8_QuqEWR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}