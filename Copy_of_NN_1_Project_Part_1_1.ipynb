{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of NN_1_Project_Part_1_1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunchek77/cars-test-/blob/main/Copy_of_NN_1_Project_Part_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnYg-nk98bSC"
      },
      "source": [
        "DOMAIN: Electronics and Telecommunication\n",
        "\n",
        "• CONTEXT: A communications equipment manufacturing company has a product which is responsible for emitting\n",
        "informative signals. Company wants to build a machine learning model which can help the company to predict the\n",
        "equipment’s signal quality using various parameters.\n",
        "\n",
        "• DATA DESCRIPTION: The data set contains information on various signal tests performed:\n",
        "\n",
        "1. Parameters: Various measurable signal parameters.\n",
        "\n",
        "2. Signal_Quality: Final signal strength or quality\n",
        "\n",
        "• PROJECT OBJECTIVE: The need is to build a regressor which can use these parameters to determine the signal strength or\n",
        "quality [as number].\n",
        "\n",
        "Steps and tasks: [ Total Score: 10 points]\n",
        "\n",
        "1. Import data.\n",
        "\n",
        "2. Data analysis & visualisation\n",
        "\n",
        "• Perform relevant and detailed statistical analysis on the data.\n",
        "\n",
        "• Perform relevant and detailed uni, bi and multi variate analysis.\n",
        "\n",
        "Hint: Use your best analytical approach. Even you can mix match columns to create new columns which can be used for better\n",
        "analysis. Create your own features if required. Be highly experimental and analytical here to find relevant hidden patterns.\n",
        "\n",
        "3. Design, train, tune and test a neural network regressor.\n",
        "\n",
        "Hint: Use best approach to refine and tune the data or the model. Be highly experimental here.\n",
        "\n",
        "4. Pickle the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjD6qwnp8Q0y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihGQ-IanxlJJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkHaArbO8kSL"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import keras as kr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential # Forward prop\n",
        "from keras.layers import Dense, Activation, LeakyReLU,ReLU\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Ve3SgQ_J0T"
      },
      "source": [
        "Setting the display layout for the coding environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcO5-C3k_Wik"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "print(\"Tensor Flow Version: \",tf.__version__)\n",
        "print(\"Keras Version: \",kr.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kRZ9ptm_ZZu"
      },
      "source": [
        "Import Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTyhQVXfLsTb"
      },
      "source": [
        "df=pd.read_csv(\"/content/Part- 1,2&3 - Signal (1).csv\")  # read csv file with \";\" as seprators\n",
        "df.head()  # Display top 5 rows of the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtjdhuD2--aN"
      },
      "source": [
        "2. Data analysis & visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E_htBO4Askz"
      },
      "source": [
        " df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PK-WUitA3c6"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn1Q-NcHA3i3"
      },
      "source": [
        "#Data type of each attribute \n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EXQNKvFBDOD"
      },
      "source": [
        "df.describe(include=\"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2DrvPEuBDYi"
      },
      "source": [
        "#Checking the presence of missing values\n",
        "df.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6b9NlSdBRZr"
      },
      "source": [
        "df.isnull().sum()   # Any of the values in the dataframe is a missing value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksidUHhiLu7"
      },
      "source": [
        "Perform relevant and detailed uni, bi and multi variate analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxZn8W85BRis"
      },
      "source": [
        "df.hist(figsize=(20,20),color=\"orange\",grid=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AqwisLshM2Z"
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6qhruLf33k"
      },
      "source": [
        "cor=df.corr()\n",
        "cor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7tABPFCgGDC"
      },
      "source": [
        "# However we want to see correlation in graphical representation so below is function for that in HEATMAP \n",
        "plt.subplots(figsize=(10,8))\n",
        "sns.heatmap(cor,annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyx1mv6Whbuu"
      },
      "source": [
        "1.Parameter 6 and Parameter 7 are highly correlated with each other and visce versa and they have almost 0 correlation with other Parameters \n",
        "\n",
        "2.Parameter 1 is positively correlated to Parameter 3 and Parameter 8 and negatively correlated to Parameter 2 and Parameter 9. \n",
        "\n",
        "3.Parameter 4 is has very low correlation with other Parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOlq1H4gGOe"
      },
      "source": [
        "sns.pairplot(df.iloc[:,1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYadjwiaiD9q"
      },
      "source": [
        "# Checking the presence of outliers\n",
        "l = len(df)\n",
        "col = list(df.columns)\n",
        "#col.remove('condition')\n",
        "for i in np.arange(len(col)):\n",
        "    sns.boxplot(x= df[col[i]], color='cyan')\n",
        "    plt.show()\n",
        "    print('Boxplot of ',col[i])\n",
        "    #calculating the outiers in attribute \n",
        "    Q1 = df[col[i]].quantile(0.25)\n",
        "    Q2 = df[col[i]].quantile(0.50)\n",
        "    Q3 = df[col[i]].quantile(0.75) \n",
        "    IQR = Q3 - Q1\n",
        "    L_W = (Q1 - 1.5 *IQR)\n",
        "    U_W = (Q3 + 1.5 *IQR)    \n",
        "    print('Q1 is : ',Q1)\n",
        "    print('Q2 is : ',Q2)\n",
        "    print('Q3 is : ',Q3)\n",
        "    print('IQR is:',IQR)\n",
        "    print('Lower Whisker, Upper Whisker : ',L_W,',',U_W)\n",
        "    bools = (df[col[i]] < (Q1 - 1.5 *IQR)) |(df[col[i]] > (Q3 + 1.5 * IQR))\n",
        "    print('Out of ',l,' rows in data, number of outliers are:',bools.sum())   #calculating the number of outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3gEgH2-hlgp"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ARnDdGrhM66"
      },
      "source": [
        "# create a boxplot for all the continuous features\n",
        "df.boxplot(column = ['Parameter 1', 'Parameter 2', 'Parameter 3', 'Parameter 4',\n",
        "       'Parameter 5', 'Parameter 6', 'Parameter 7', 'Parameter 8',\n",
        "       'Parameter 9', 'Parameter 10', 'Parameter 11', 'Signal_Strength'], figsize = (20,10)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM9vI22FhWba"
      },
      "source": [
        "we see outliers in almost very parameter however highest in 4,6,7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA6_8Y4ric45"
      },
      "source": [
        "Design, train, tune and test a neural network regressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgYnvFUshxLz"
      },
      "source": [
        "X = df.drop(\"Signal_Strength\", axis=1)\n",
        "y = df['Signal_Strength']             \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91aO7RDRY2Gi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitting to create test data\n",
        "X_vtrain, X_test, y_vtrain, y_test = train_test_split(X, y, test_size=.20, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIh9n1PkY-eA"
      },
      "source": [
        "X_vtrain.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQsUGmhYkmlV"
      },
      "source": [
        "#Check number of test examples and size of each example\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dRbRnzlfd6"
      },
      "source": [
        "#Check number of training examples and size of each example\n",
        "print(y_vtrain.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTTtb6CIlZxe"
      },
      "source": [
        "#Check number of test examples and size of each example\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDmDhVoJZVV7"
      },
      "source": [
        "# splitting to create training and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_vtrain, y_vtrain, test_size=.20, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CepzDtFLZaQN"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZjDxudWltN9"
      },
      "source": [
        "Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bqVtw7alZ0z"
      },
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAJx_gdj2opN"
      },
      "source": [
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(11,)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AizciyjBms-w"
      },
      "source": [
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(100,kernel_initializer='normal', activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aty4KT36mtB9"
      },
      "source": [
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(60,kernel_initializer='normal', activation='relu'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjACypwKmtE3"
      },
      "source": [
        "#Add 3rd hidden layer\n",
        "model.add(tf.keras.layers.Dense(32,kernel_initializer='normal', activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jx1t6w3mtHj"
      },
      "source": [
        "#Add 4th hidden layer\n",
        "model.add(tf.keras.layers.Dense(16,kernel_initializer='normal', activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcAL9hIkmtK6"
      },
      "source": [
        "#Add OUTPUT layer\n",
        "model.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrQraM80mtNA"
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam',loss='mean_absolute_error', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVOgQrBtoXvw"
      },
      "source": [
        "Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLJlhW74oXFR"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLQF5G8SrfRA"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndh9PKhLrpP_"
      },
      "source": [
        "   EPOCH=300\n",
        "model_reg= model.fit(X_train, y_train,          \n",
        "          validation_data=(X_val,y_val),\n",
        "          epochs= EPOCH,\n",
        "          batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Eyl4vf0BD-"
      },
      "source": [
        "loss_train = model_reg.history['loss']\n",
        "loss_val = model_reg.history['val_loss']\n",
        "epochs = range(1,EPOCH+1)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flgcXcJP97AV"
      },
      "source": [
        "Acc_train = model_reg.history['accuracy']\n",
        "Acc_val = model_reg.history['val_accuracy']\n",
        "epochs = range(1,EPOCH+1)\n",
        "plt.plot(epochs, Acc_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, Acc_val, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N10xFEQkdBSq"
      },
      "source": [
        "Pickle the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix4tUk5agC2s"
      },
      "source": [
        "from keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgzlQYszcoL_"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHJjTZn7cVfE"
      },
      "source": [
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkR7FIZ-cjgA"
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json (loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LffDia8lDtc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNul5iOFgOl4"
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Pqkdq8ghc5"
      },
      "source": [
        "print(y_pred[0])\n",
        "print(y_pred[1])\n",
        "print(y_pred[2])\n",
        "print(y_pred[3])\n",
        "print(y_pred[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzPJkhr0gh-p"
      },
      "source": [
        "print(y_test.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}